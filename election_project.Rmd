---
title: "2016-2012 Election Modeling"
output:
  html_document: default
  html_notebook: default
  pdf_document: default
---




A noteable occurance of the 2016 election was the large number of counties whom voted for Obama in 2012, and then switched to Trump in 2016. After the election, I was curious if there were common factors uniting counties which had voted for such seemingly opposite candidates within 4 years of each other- and if so, what were they, and what could we learn from them? First, let's scrape results. Our 2016 results come courtesy of the AP, with some help from Python, and our 2012 results come courtesy of the Huffington Post, with bit of help from Unix. There is a Python script in this folder which does the scraping for us. 
Now that we've extracted everything from the AP's live feed, we should still probably clean everything and also grab our 2012 results. 

```{r, warning=FALSE, message=FALSE}
 library(readr)
require(ggplot2)
require(dplyr)
require(magrittr)
results_16 <- read_csv("~/Election-Model/results_16.csv", 
    col_types = cols(X1 = col_skip()))
 colnames(results_16)<-c("State_FIPS", "pct_reporting", "Candidate", "Votes")
 require(reshape2)
 # The results we scrape from the AP are in long format,we want them in wide format
 results_16<-dcast(results_16, State_FIPS ~ Candidate, value.var = "Votes") %>% mutate(FIPS = substring(State_FIPS, 3), vote_share_dem_16 = `Hillary Clinton`/(`Donald Trump`+ `Hillary Clinton`))
```

So now that we've cleaned our 2016 results, we need to get our 2012 results. These are scraped from the Huffington posts's github-but they come in state-by-state CSVs- just takes a bit of command-line trickery to concatenate them.  

```{r, warning=FALSE, message=FALSE}
#system("cd ..; cd election-2012-results; cd data; cat *.csv > results_12_merged.csv")
# Only run this once, unless you want multiple election results in the same folder

results_12 <- read_csv("~/election-2012-results/data/results_12_merged.csv")
results_12<-results_12[results_12$fips!="fips", ]
results_12$votes<-as.numeric(results_12$votes)
results_12<-dcast(results_12, fips ~ candidate, value.var = "votes", fun.aggregate = sum)
results_12$R_Totals<-rowSums(results_12[,169:180]) + rowSums(results_12[,219:231])
results_12$D_Totals<-rowSums(results_12[,17:28]) + rowSums(results_12[,184:196])
results_12$vote_share_dem_12<-results_12$D_Totals/(results_12$D_Totals + results_12$R_Totals)
results_12<-as.data.frame(cbind(results_12$fips, results_12$vote_share_dem_12))
colnames(results_12)<-c("fips", "vote_share_dem_12" )
require(sqldf)
# joining our results by fips. 
county_results_16_12<-sqldf("select a.fips, a.vote_share_dem_12, b.vote_share_dem_16 from results_16 b left join results_12 a on b.FIPS=a.fips")
county_results_16_12<-county_results_16_12[!is.na(county_results_16_12$fips),]
plot(county_results_16_12$vote_share_dem_12, county_results_16_12$vote_share_dem_16)
```
This gives us a good indication of the correlation between 2012 and 2016 vote share- Let's append some census data onto everything, and see how it goes. It is important to note that the Census data is from the 2015 ACS Survey. This is important for two reasons. The first one is that I wanted the most up-to-date census data, and the second is that the 2015 ACS covered only 830 of the of the most populous counties, (all counties with population over 65,000), as opposed to the 3,143 counties in the United States. I felt was important to avoid overfitting to outliers present in the wide range of counties avaliable, and that it would be a more up-to-date and representative sample of the American electorate. 

```{r, warning=FALSE, message=FALSE}
require(acs)
api.key.install(key="611c5793e128f8732eb50b465ca7689481a4ca8e")
all_counties<-geo.make(state="*",county="*")
race_table<-acs.fetch(endyear = 2015, span=1, geography = all_counties, table.number = "B02001", col.names = "pretty")
hispanic_table<-acs.fetch(endyear = 2015, span=1, geography = all_counties, table.number = "B03003", col.names = "pretty")
income_table<-acs.fetch(endyear = 2015, span = 1, geography = all_counties, table.number = "B19001", col.names="pretty")
education_table<-acs.fetch(endyear = 2015, span=1, geography = all_counties, table.number = "B15003", col.names = "pretty")
employment_table<-acs.fetch(endyear=2015, span = 1, geography = all_counties, table.number = "B23025", col.names = "pretty")
gender_age_table<-acs.fetch(endyear=2015, span = 1, geography = all_counties, table.number = "B01001", col.names = "pretty")
marital_table<-acs.fetch(endyear=2015, span = 1, geography = all_counties, table.number = "B12001", col.names = "pretty")

# function for taking an ACS table, turning total counts into proportions, and turning it into a data frame with fips appended. 
Clean_ACS<-function(table_name){
  estimate_mat<-estimate(table_name)
  estimate_table<-as.data.frame(prop.table(estimate_mat[,2:ncol(estimate_mat)],1))
  estimate_table$id<-rownames(estimate_table)
  geo_table<-as.data.frame(geography(table_name))
  joined_table<-sqldf("Select a.*, b.* from geo_table a left join estimate_table b on a.NAME=b.id")
  joined_table<-joined_table[,1:(ncol(joined_table)-1)]
  joined_table$fips<-paste0(str_pad(joined_table$state, width=2, side="left", pad="0"), joined_table$county)
  return(joined_table)
}

race_df<-Clean_ACS(race_table)
hispanic_df<-Clean_ACS(hispanic_table)
income_df<-Clean_ACS(income_table)
education_df<-Clean_ACS(education_table)
emp_df<-Clean_ACS(employment_table)
gender_age_df<-Clean_ACS(gender_age_table)
marital_df<-Clean_ACS(marital_table)

all_acs_data<-cbind(race_df, hispanic_df[4:(ncol(hispanic_df)-1)], income_df[4:(ncol(income_df)-1)], education_df[4:(ncol(education_df)-1)],emp_df[4:(ncol(emp_df)-1)],gender_age_df[4:(ncol(gender_age_df)-1)],
                    marital_df[4:(ncol(marital_df)-1)] )

require(dplyr)
acs_results<-dplyr::left_join(all_acs_data, county_results_16_12, by=c('fips'='fips'))


```

Great, now we have it all appended. Let's do some descriptive statistics 


```{r, warning=FALSE, message=FALSE}
acs_results$vote_share_dem_12<-as.numeric(acs_results$vote_share_dem_12)
acs_results$diff<-acs_results$vote_share_dem_16-acs_results$vote_share_dem_12
mean(acs_results$diff, na.rm = TRUE)
sd(acs_results$diff, na.rm = TRUE)
plot(density(acs_results$diff, na.rm=TRUE))
acs_results_model<-acs_results[!is.na(acs_results$diff),]
```

Let's try to model a binary outcome- Run a model to predict what caused a county to switch to voting Republican in 2016.

```{r, warning=FALSE, message=FALSE}
require(caret)
require(glmnet)
require(pROC)
require(Matrix)
require(ROCR)
set.seed(7)

for(i in 1:ncol(acs_results_model)){
  acs_results_model[is.na(acs_results_model[,i]), i] <- mean(acs_results_model[,i], na.rm = TRUE)
}
acs_df<-as.data.frame(acs_results_model)
acs_df$flipped<-ifelse(acs_df$diff<0, "y", "n")
exclude.vars<-c("NAME", "state", "county", "vote_share_dem_12", "vote_share_dem_16", "diff", "fips")
acs_df = acs_df[,!(names(acs_df) %in% exclude.vars)]
reg.var<-"flipped"
partition_rows<-createDataPartition(acs_df[, reg.var], p=.7, list=FALSE, times=1)
acs_train<-acs_df[partition_rows,]
acs_test<-acs_df[-partition_rows,]
flip_model = cv.glmnet(as.matrix(acs_train[,1:ncol(acs_train)-1]), acs_train$flipped, family="binomial", type.measure = "auc", alpha=0.4)
acs_test$fitted<-predict(flip_model, newx = as.matrix(acs_test[,1:ncol(acs_test)-1]), type="response", s="lambda.min")
pred<-prediction(acs_test$fitted, acs_test$flipped)
perf <- performance(pred,"tpr","fpr")
auc_perf<-performance(pred,"auc")
plot(perf,colorize=FALSE, col="black")
paste("The Model has an AUC of",  round(as.numeric(auc_perf@y.values), 2))

```

AUC looks good on our model of predicted flips- indicating that census data serves as an accurate classifier for whether or not counties flipped in their voting. What's important to note isn't really the model- not too much point in trying to predict what already happened, but we can learn a lot from creating this model- specifically, what are the biggest influencers in a county switching from 2012-2016? 

```{r, fig.height=5, fig.width=10, warning=FALSE, message=FALSE}
flip_coeffs<-coef.cv.glmnet(flip_model)
tmp<-as.data.frame(as.matrix(flip_coeffs))
tmp$factor<-rownames(tmp)
colnames(tmp)<-c("coeff", "factor_name")
tmp<-tmp[tmp$coeff!=0,]
imp_plot<-ggplot(data=tmp, aes(x=reorder(factor_name, coeff), y=coeff)) +
  geom_bar(stat="identity") + coord_flip()+theme(axis.text=element_text(size=6),
        axis.title=element_text(size=8,face="bold")) + ylab("CV GLMNET Coeffecient: Positive values indicate high influence on whether counties flipped ") + xlab("Census Category") + ggtitle("Census Categories \n by CV GLMNET Coeffecient")
imp_plot
```


What stands out: education, age, and gender seem to carry the most weight when determining which counties stayed Democratic, and which ones did not. There is a marked split between people with two year college degrees and people with four year college degrees- which suggests that a four year college degree is really the tipping point at which education affects partisanship. Furthermore, I think that the high weights of both widowed men and women suggest serve as proxies for age and income- people whom are older are more likley to be widowed, and people who have lower income are more likely to have shorter lifespans, which would create relatively high amounts of widows in the population. To me, the most interesting part is that in an election where a common theme was racial political polarization, race seemed to play a small role in determining which counties flipped Republican, compared with overall education, age and gender. All together, it can easily be gleaned through the coeffecients where the crack in the 'Obama Coalition' formed, and where they held steady. Low-educated males over 50 showed high levels of changing voting patterns from Obama to Trump, while those whom held the most consistent were most likely well-educated females under 35. Through applying this type of analysis to similar problems, it will also be possible to extrapolate indicators for downballot ticket splitting. In the case of North Carolina, this presents high potential for understanding exactly the effects which led to Donald Trump winning the state on the presidential level, but Pat McRory losing a close race for governor. For Democrats, both this analysis, and the potential analysis of North Carolina should give insights into which voters are necessary to retain in the Democratic coalition, as well as which voters show potential for voting Democratic at the presidential level, rather than just the gubernatorial level. 